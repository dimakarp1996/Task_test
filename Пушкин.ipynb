{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import gensim.function\n",
    "\n",
    "text=open('Стихи.txt','r').readlines()\n",
    "text = [i for i in text if i != '' and 'Стихотворения' not in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [i.strip() for i in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [i for i in text if i != '' and 'Стихотворения' not in i]\n",
    "text = text[:len(text)-243]\n",
    "data=''.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "603368"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.replace('\\xa0',' ')\n",
    "\n",
    "for number in '123456789':\n",
    "    data=data.replace(number,'0')\n",
    "for english_letter in 'ABCDEFGHIJKLMNOPQRSTUVWXYZ':\n",
    "    data=data.replace(english_letter, '')\n",
    "for english_letter in 'abcdefghijklmnopqrstuvwzyz':\n",
    "    data=data.replace(english_letter, '')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=set(data)\n",
    "c=dict()\n",
    "for symbol in b:\n",
    "    c[symbol] = data.count(symbol)\n",
    "import operator\n",
    "c1 = sorted(c.items(), key=operator.itemgetter(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<мз;И[-„бтюМй)О–,г\"(н\\'еК«цсы…БФ/xвлЧ#_оПХхУЗШЦипэЩЛаЮшВ?яС А&ьфГЖ:Э>*.р]Е0РЯ»учДТщ—НкжЙёъд!'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Alphabet =''.join(c.keys())\n",
    "Alphabet\n",
    "#We don't delete any of the chars as now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_first=True\n",
    "def string_vectorizer(string, alphabet=Alphabet):\n",
    "    vector = [[0 if char != letter else 1 for char in Alphabet] \n",
    "                  for letter in string]\n",
    "    return vector\n",
    "def vector_stringizer(vector, alphabet = Alphabet):\n",
    "    answ=''\n",
    "    if return_first:\n",
    "        index = vector.argsort()[-1]\n",
    "        answ+=Alphabet[index]\n",
    "    else:\n",
    "        index = vector.argsort()[-2]\n",
    "        answ+=Alphabet[index]\n",
    "    return answ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_onehot = string_vectorizer(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DK\\Anaconda3.1\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM,Flatten\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "#from tqdm import tqdm\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_len = 15\n",
    "X_total,Y_total=[],[]\n",
    "i=1000\n",
    "X_total.append(data_onehot[i-window_len:i])\n",
    "Y_total.append(data_onehot[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(data_onehot):\n",
    "    X_total,Y_total=[],[]\n",
    "    for i in range(window_len, len(data_onehot)):\n",
    "        X_total.append(data_onehot[i-window_len:i])\n",
    "        Y_total.append(data_onehot[i])\n",
    "    return np.array(X_total), np.array(Y_total)\n",
    "X_total, Y_total=make_dataset(data_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(595977, 15, 91)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_total.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(X_total, Y_total, test_size=0.15, random_state = 1)\n",
    "del X_total\n",
    "del  Y_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  keras.callbacks import EarlyStopping\n",
    "callback = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_8 (LSTM)                (None, 15, 100)           76800     \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 1500)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 91)                136591    \n",
      "=================================================================\n",
      "Total params: 213,391\n",
      "Trainable params: 213,391\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 506580 samples, validate on 89397 samples\n",
      "Epoch 1/20\n",
      "506580/506580 [==============================] - 920s 2ms/step - loss: 0.0368 - val_loss: 0.0341\n",
      "Epoch 2/20\n",
      "506580/506580 [==============================] - 885s 2ms/step - loss: 0.0329 - val_loss: 0.0324\n",
      "Epoch 3/20\n",
      "506580/506580 [==============================] - 931s 2ms/step - loss: 0.0315 - val_loss: 0.0317\n",
      "Epoch 4/20\n",
      "506580/506580 [==============================] - 946s 2ms/step - loss: 0.0306 - val_loss: 0.0313\n",
      "Epoch 5/20\n",
      "506580/506580 [==============================] - 946s 2ms/step - loss: 0.0300 - val_loss: 0.0312\n",
      "Epoch 6/20\n",
      "506580/506580 [==============================] - 891s 2ms/step - loss: 0.0295 - val_loss: 0.0309\n",
      "Epoch 7/20\n",
      "506580/506580 [==============================] - 37873s 75ms/step - loss: 0.0292 - val_loss: 0.0308\n",
      "Epoch 8/20\n",
      "506580/506580 [==============================] - 735s 1ms/step - loss: 0.0289 - val_loss: 0.0307\n",
      "Epoch 9/20\n",
      "506580/506580 [==============================] - 784s 2ms/step - loss: 0.0287 - val_loss: 0.0308\n",
      "Epoch 10/20\n",
      " 36990/506580 [=>............................] - ETA: 11:14 - loss: 0.0277"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-83-186b8b743898>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3.1\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 963\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    964\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3.1\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1705\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3.1\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1235\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1236\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3.1\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2478\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2479\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3.1\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3.1\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1135\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1137\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1138\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3.1\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1353\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1355\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1356\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1357\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3.1\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1359\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1360\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1361\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1362\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3.1\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1338\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[1;32m-> 1340\u001b[1;33m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[0;32m   1341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(window_len, len(Alphabet)), return_sequences=True))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(len(Alphabet),activation='softmax'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "model.summary()\n",
    "model.fit(X_train,Y_train, epochs=20,validation_data = (X_test, Y_test), batch_size=10, verbose=1,callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Pushkin1.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "  # deletes the existing model\n",
    "\n",
    "# returns a compiled model\n",
    "# identical to the previous one\n",
    "#model = load_model('Pushkin1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Уж небо осенью '\n",
    "from copy import deepcopy\n",
    "text1 = deepcopy(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted 0 letters \n",
      "Predicted 20 letters \n",
      "Predicted 40 letters \n",
      "Predicted 60 letters \n",
      "Predicted 80 letters \n",
      "Predicted 100 letters \n",
      "Predicted 120 letters \n",
      "Predicted 140 letters \n",
      "Predicted 160 letters \n",
      "Predicted 180 letters \n",
      "Predicted 200 letters \n",
      "Predicted 220 letters \n",
      "Predicted 240 letters \n",
      "Predicted 260 letters \n",
      "Predicted 280 letters \n",
      "Predicted 300 letters \n",
      "Predicted 320 letters \n",
      "Predicted 340 letters \n",
      "Predicted 360 letters \n",
      "Predicted 380 letters \n",
      "Predicted 400 letters \n",
      "Predicted 420 letters \n",
      "Predicted 440 letters \n",
      "Predicted 460 letters \n",
      "Predicted 480 letters \n",
      "Predicted 500 letters \n",
      "Predicted 520 letters \n",
      "Predicted 540 letters \n",
      "Predicted 560 letters \n",
      "Predicted 580 letters \n",
      "Predicted 600 letters \n",
      "Predicted 620 letters \n",
      "Predicted 640 letters \n",
      "Predicted 660 letters \n",
      "Predicted 680 letters \n",
      "Predicted 700 letters \n",
      "Predicted 720 letters \n",
      "Predicted 740 letters \n",
      "Predicted 760 letters \n",
      "Predicted 780 letters \n",
      "Predicted 800 letters \n",
      "Predicted 820 letters \n",
      "Predicted 840 letters \n",
      "Predicted 860 letters \n",
      "Predicted 880 letters \n",
      "Predicted 900 letters \n",
      "Predicted 920 letters \n",
      "Predicted 940 letters \n",
      "Predicted 960 letters \n",
      "Predicted 980 letters \n",
      "Уж небо осенью тобой.И вдруг и старик последний свободы не стала в силах восторгом забытый под стол мой друг, и сладостный поэт!То в сердце приветственный край сиял,Странал мой кругом,И постали в приятным столицы молодой,И сладостный покров и сладострастный под стол мой друг, и сладостный поэт!То в сердце приветственный край сиял,Странал мой кругом,И постали в приятным столицы молодой,И сладостный покров и сладострастный под стол мой друг, и сладостный поэт!То в сердце приветственный край сиял,Странал мой кругом,И постали в приятным столицы молодой,И сладостный покров и сладострастный под стол мой друг, и сладостный поэт!То в сердце приветственный край сиял,Странал мой кругом,И постали в приятным столицы молодой,И сладостный покров и сладострастный под стол мой друг, и сладостный поэт!То в сердце приветственный край сиял,Странал мой кругом,И постали в приятным столицы молодой,И сладостный покров и сладострастный под стол мой друг, и сладостный поэт!То в сердце приветственный край сиял,Странал мой кру\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    text_array = np.array(string_vectorizer(text1)).reshape(1,window_len,91)\n",
    "    predicted_vector = model.predict(text_array)\n",
    "    predicted_char = vector_stringizer(predicted_vector[0])\n",
    "    text = text+predicted_char\n",
    "    text1 = text1[1:]+predicted_char\n",
    "    if i%20==0:\n",
    "        print('Predicted '+str(i)+' letters ')\n",
    "print(text)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'юблю тебя петра'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.68948383e-06, 1.32726545e-05, 1.82559847e-06, 5.59600792e-08,\n",
       "        2.20814101e-07, 7.16160597e-09, 2.55149729e-07, 4.22420143e-08,\n",
       "        4.58443792e-05, 6.15662866e-05, 9.85079751e-05, 1.48894244e-07,\n",
       "        3.93421760e-06, 3.15374322e-08, 3.22220359e-07, 5.34448681e-08,\n",
       "        7.25990731e-07, 4.61424497e-06, 5.46918208e-08, 8.29758804e-08,\n",
       "        2.10189231e-04, 1.31498927e-08, 5.75646199e-02, 2.25692972e-07,\n",
       "        6.55047172e-09, 2.34680101e-06, 1.94769200e-06, 4.35431662e-04,\n",
       "        1.94357000e-07, 1.25667754e-07, 6.80677985e-08, 2.21273226e-07,\n",
       "        4.01492422e-08, 1.18674041e-04, 4.41178243e-04, 1.91478033e-08,\n",
       "        1.08824838e-09, 2.18117748e-07, 1.45933572e-02, 4.10452827e-07,\n",
       "        4.09753333e-08, 6.03189983e-06, 1.65799037e-07, 3.21344977e-08,\n",
       "        1.38635405e-08, 3.26991163e-08, 1.05397692e-02, 4.81374354e-06,\n",
       "        1.13914083e-07, 5.94952780e-08, 7.33801713e-08, 2.23718937e-02,\n",
       "        7.89767469e-08, 1.57684171e-05, 1.66292452e-07, 1.64414985e-07,\n",
       "        1.73066126e-03, 2.42689453e-07, 2.47361777e-06, 1.01021897e-06,\n",
       "        1.36948142e-08, 6.17426736e-07, 2.46855197e-05, 1.66164995e-07,\n",
       "        2.22948728e-07, 9.67388658e-08, 3.64080144e-08, 4.43160530e-08,\n",
       "        3.30470084e-06, 2.27512464e-06, 5.81200984e-05, 7.98573069e-07,\n",
       "        8.40962926e-08, 1.15950388e-06, 5.62022535e-08, 3.01788745e-08,\n",
       "        1.20351444e-07, 8.91570628e-01, 1.19641777e-06, 7.47101012e-08,\n",
       "        1.75898990e-07, 5.38573559e-08, 9.44633172e-08, 9.87590738e-08,\n",
       "        3.37912461e-05, 1.47792907e-05, 1.46526524e-08, 5.69893473e-06,\n",
       "        2.65521294e-07, 1.85890849e-06, 1.92386366e-07]], dtype=float32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'у'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'у'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
