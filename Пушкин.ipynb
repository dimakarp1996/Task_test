{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import gensim.function\n",
    "\n",
    "text=open('Стихи.txt','r').readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [i.strip() for i in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [i for i in text if i != '' and 'Стихотворения' not in i]\n",
    "text = text[:len(text)-243]\n",
    "data=''.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "603368"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.replace('\\xa0',' ')\n",
    "\n",
    "for number in '123456789':\n",
    "    data=data.replace(number,'0')\n",
    "for english_letter in 'ABCDEFGHIJKLMNOPQRSTUVWXYZ':\n",
    "    data=data.replace(english_letter, '')\n",
    "for english_letter in 'abcdefghijklmnopqrstuvwzyz':\n",
    "    data=data.replace(english_letter, '')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=set(data)\n",
    "c=dict()\n",
    "for symbol in b:\n",
    "    c[symbol] = data.count(symbol)\n",
    "import operator\n",
    "c1 = sorted(c.items(), key=operator.itemgetter(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ш?ъя: «Щы)ЖЧЭ\\'>чщХ;…Ни&<жПьвз(ЙюКйпВОдАЗЦГ–Б0,шФр[—м_цнЮ#фМэх-]Д!Стб„г/УРxуТЛИ\"л*кёса»ЕЯо.е'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Alphabet =''.join(c.keys())\n",
    "Alphabet\n",
    "#We don't delete any of the chars as now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def string_vectorizer(string, alphabet=Alphabet):\n",
    "    vector = [[0 if char != letter else 1 for char in Alphabet] \n",
    "                  for letter in string]\n",
    "    return vector\n",
    "def vector_stringizer(vector, alphabet = Alphabet,return_first=True):\n",
    "    answ=''\n",
    "    if return_first:\n",
    "        index = vector.argsort()[-1]\n",
    "        answ+=Alphabet[index]\n",
    "    else:\n",
    "        index = vector.argsort()[-2]\n",
    "        answ+=Alphabet[index]\n",
    "    return answ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_onehot = string_vectorizer(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DK\\Anaconda3.1\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM,Flatten,Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "#from tqdm import tqdm\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_len = 15\n",
    "X_total,Y_total=[],[]\n",
    "i=1000\n",
    "X_total.append(data_onehot[i-window_len:i])\n",
    "Y_total.append(data_onehot[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(data_onehot):\n",
    "    X_total,Y_total=[],[]\n",
    "    for i in range(window_len, len(data_onehot)):\n",
    "        X_total.append(data_onehot[i-window_len:i])\n",
    "        Y_total.append(data_onehot[i])\n",
    "    return np.array(X_total), np.array(Y_total)\n",
    "X_total, Y_total=make_dataset(data_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(595977, 15, 91)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_total.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(X_total, Y_total, test_size=0.15, random_state = 1)\n",
    "del X_total\n",
    "del  Y_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  keras.callbacks import EarlyStopping\n",
    "callback = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(window_len, len(Alphabet)), return_sequences=True))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(len(Alphabet),activation='softmax'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "model.summary()\n",
    "model.fit(X_train,Y_train, epochs=20,validation_data = (X_test, Y_test), batch_size=10, verbose=1,callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Pushkin1.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "  # deletes the existing model\n",
    "\n",
    "# returns a compiled model\n",
    "# identical to the previous one\n",
    "#model = load_model('Pushkin1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Уж небо осенью '\n",
    "from copy import deepcopy\n",
    "text1 = deepcopy(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предсказываем наиболее вероятную букву"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Уж небо осенью тобой.И вдруг и старик последний свободы не стала в силах восторгом забытый под стол мой друг, и сладостный поэт!То в сердце приветственный край сиял,Странал мой кругом,И постали в приятным столицы молодой,И сладостный покров и сладострастный под стол мой друг, и сладостный поэт!То в сердце приветственный край сиял,Странал мой кругом,И постали в приятным столицы молодой,И сладостный покров и сладострастный под стол мой друг, и сладостный поэт!То в сердце приветственный край сиял,Странал мой кругом,И постали в приятным столицы молодой,И сладостный покров и сладострастный под стол мой друг, и сладостный поэт!То в сердце приветственный край сиял,Странал мой кругом,И постали в приятным столицы молодой,И сладостный покров и сладострастный под стол мой друг, и сладостный поэт!То в сердце приветственный край сиял,Странал мой кругом,И постали в приятным столицы молодой,И сладостный покров и сладострастный под стол мой друг, и сладостный поэт!То в сердце приветственный край сиял,Странал мой кругом,И постали в приятным столицы молодой,И сладостный покров и сладострастный под стол мой друг, и сладостный поэт!То в сердце приветственный край сиял,Странал мой кругом,И постали в приятным столицы молодой,И сладостный покров и сладострастный под стол мой друг, и сладостный поэт!То в сердце приветственный край сиял,Странал мой кругом,И постали в приятным столицы молодой,И сладостный покров и сладострастный под стол мой друг, и сладостный поэт!То в сердце приветственный край сиял,Странал мой кругом,И постали в приятным столицы молодой,И сладостный покров и сладострастный под стол мой друг, и сладостный поэт!То в сердце приветственный край сиял,Странал мой кругом,И постали в приятным столицы молодой,И сладостный покров и сладострастный под стол мой друг, и сладостный поэт!То в сердце приветственный край сиял,Странал мой кругом,И постали в приятным столицы молодой,И сладостный покров и сладострастный под стол мой друг, и сладостный поэт!То в сердце приветственный край сиял,Странал мой к\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    text_array = np.array(string_vectorizer(text1)).reshape(1,window_len,91)\n",
    "    predicted_vector = model.predict(text_array)\n",
    "    predicted_char = vector_stringizer(predicted_vector[0])\n",
    "    text = text+predicted_char\n",
    "    text1 = text1[1:]+predicted_char\n",
    "    #if i%20==0:\n",
    "        #print('Predicted '+str(i)+' letters ')\n",
    "print(text)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Уж небо осенью '\n",
    "text1 = deepcopy(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предсказываем вторую по вероятности букву"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Уж небо осенью свенцы, вечно тем прельем, прездучивых,Изманы,Помнешнному,Стоя поэзь тревеще небо в тем нахмерелых, скорее прелосая, всё,Всемурощей,Но,,Неталямь своей,Истиг в послуждалскою,Несестителях,Их,[час на стигах,Смолотен мирногде, никуплата нежиною твеяжь в придаю,Измалася,Дрогарайска прияжно мною послужны души,Или,Чадал из ни слог незносадей,Невинов днему.Явлеющей,Или,,С свердницами,С какновики,Возвождатей,Невиненно слогой,Или,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    text_array = np.array(string_vectorizer(text1)).reshape(1,window_len,91)\n",
    "    predicted_vector = model.predict(text_array)\n",
    "    predicted_char = vector_stringizer(predicted_vector[0], return_first=False)\n",
    "    text = text+predicted_char\n",
    "    text1 = text1[1:]+predicted_char\n",
    "    #if i%20==0:\n",
    "        #print('Predicted '+str(i)+' letters ')\n",
    "print(text) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предсказываем наиболее вероятную букву, но не всегда."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Уж небо осенью столь, и тому подъемлет он в сень на постали мой друг, и славы постали в прах веселых под шумит,И все дару под сень на свободы не стала,И сладостный простой пред тобы томный старик последний свобы в силой друг,В том за староских последний стал и сладость в полязу под себя возвышенный свободы,На моренья милый друг,Придать в свои под сень мой драгой старик постали в приходит,Он в своей прелестной полной старик последним простой мой долго страстной старик под сень на стал и старого столеты,В мечтанье старик и столковал он в пред ним столем постали в прах веселых под шумит,И все дару под сень на свободы не стала,И сладостный простой пред тобы томный старик последний свобы в силой друг,В том за староских последний стал и сладость в полязу под себя возвышенный свободы,На моренья милый друг,Придать в свои под сень мой драгой старик постали в приходит,Он в своей прелестной полной старик последним простой мой долго страстной старик под сень на стал и старого столеты,В мечтанье старик и столкова\n"
     ]
    }
   ],
   "source": [
    "text = 'Уж небо осенью '\n",
    "text1 = deepcopy(text)\n",
    "for i in range(1000):\n",
    "    text_array = np.array(string_vectorizer(text1)).reshape(1,window_len,91)\n",
    "    predicted_vector = model.predict(text_array)\n",
    "    if i%15!=0:\n",
    "        predicted_char = vector_stringizer(predicted_vector[0], return_first=True)\n",
    "    else:\n",
    "        predicted_char = vector_stringizer(predicted_vector[0], return_first=False)\n",
    "    text = text+predicted_char\n",
    "    text1 = text1[1:]+predicted_char\n",
    "    #if i%20==0:\n",
    "        #print('Predicted '+str(i)+' letters ')\n",
    "print(text) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все равно циклится. А если выбирать вторую букву вместо первой не всегда,а более-менее рандомно?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Уж небо осенью тоба восторгом полетит, и странник мой,Как был под слезы просто полной старик послушный,Над собности подавал в приятной другием восторгом стоит простой мой друг, и сладостный, не страдал восторгом столом полетит,И в сердца и старик,Но ты, как девица страдала.Стал и сладостной постали в пред колени полный светил восторгом столетом заботы,На стану в молчанье, восторгом столом последний расстал и полнощный сводом.И странный, воскресный поэт,Но с подруги полной старик последний свободы не стали в полезный под сени, столицы стол,На полны на странного страдал, от бранный старик последний свои постали, не стройный красной?Ужель ужа ли в столе приведет.Посталься в другим столиться, в столе мой придет от приведеньем последний свободы не стала проститься на кругом полетит,И старик мой проститель полетели,И все не страда вознастить, постали в приятным столицы молитвый,В получил с невозок на странник старик, под скалоть, мой друг, издаливый свобы в сили в постеле под сень мира,И странник молодой,С\n"
     ]
    }
   ],
   "source": [
    "text = 'Уж небо осенью '\n",
    "text1 = deepcopy(text)\n",
    "from numpy import random\n",
    "random.seed(0)\n",
    "for i in range(1000):\n",
    "    text_array = np.array(string_vectorizer(text1)).reshape(1,window_len,91)\n",
    "    predicted_vector = model.predict(text_array)\n",
    "    j = random.randint(0,30)\n",
    "    if j%25!=0:\n",
    "        predicted_char = vector_stringizer(predicted_vector[0], return_first=True)\n",
    "    else:\n",
    "        predicted_char = vector_stringizer(predicted_vector[0], return_first=False)\n",
    "    text = text+predicted_char\n",
    "    text1 = text1[1:]+predicted_char\n",
    "    #if i%20==0:\n",
    "        #print('Predicted '+str(i)+' letters ')\n",
    "print(text) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тоже бред, но по крайней мере не циклится. Уже лучше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дубль два. Учим более сложную модель, но с дропаутом. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 15, 120)           101760    \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 1800)              0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1800)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 91)                163891    \n",
      "=================================================================\n",
      "Total params: 265,651\n",
      "Trainable params: 265,651\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 506580 samples, validate on 89397 samples\n",
      "Epoch 1/20\n",
      "506580/506580 [==============================] - 530s 1ms/step - loss: 0.0371 - val_loss: 0.0342\n",
      "Epoch 2/20\n",
      "506580/506580 [==============================] - 547s 1ms/step - loss: 0.0334 - val_loss: 0.0325\n",
      "Epoch 3/20\n",
      "506580/506580 [==============================] - 623s 1ms/step - loss: 0.0319 - val_loss: 0.0315\n",
      "Epoch 4/20\n",
      "506580/506580 [==============================] - 574s 1ms/step - loss: 0.0310 - val_loss: 0.0311\n",
      "Epoch 5/20\n",
      "506580/506580 [==============================] - 565s 1ms/step - loss: 0.0305 - val_loss: 0.0308\n",
      "Epoch 6/20\n",
      "506580/506580 [==============================] - 576s 1ms/step - loss: 0.0300 - val_loss: 0.0306\n",
      "Epoch 7/20\n",
      "506580/506580 [==============================] - 517s 1ms/step - loss: 0.0297 - val_loss: 0.0305\n",
      "Epoch 8/20\n",
      "506580/506580 [==============================] - 535s 1ms/step - loss: 0.0294 - val_loss: 0.0304\n",
      "Epoch 9/20\n",
      "506580/506580 [==============================] - 648s 1ms/step - loss: 0.0291 - val_loss: 0.0302\n",
      "Epoch 10/20\n",
      "506580/506580 [==============================] - 536s 1ms/step - loss: 0.0290 - val_loss: 0.0302\n",
      "Epoch 11/20\n",
      "506580/506580 [==============================] - 553s 1ms/step - loss: 0.0288 - val_loss: 0.0302\n",
      "Epoch 12/20\n",
      "506580/506580 [==============================] - 572s 1ms/step - loss: 0.0286 - val_loss: 0.0302\n",
      "Epoch 13/20\n",
      "506580/506580 [==============================] - 513s 1ms/step - loss: 0.0285 - val_loss: 0.0302\n",
      "Epoch 14/20\n",
      "506580/506580 [==============================] - 499s 984us/step - loss: 0.0284 - val_loss: 0.0301\n",
      "Epoch 15/20\n",
      "506580/506580 [==============================] - 487s 962us/step - loss: 0.0282 - val_loss: 0.0301\n",
      "Epoch 16/20\n",
      "506580/506580 [==============================] - 492s 972us/step - loss: 0.0281 - val_loss: 0.0301\n",
      "Epoch 17/20\n",
      "506580/506580 [==============================] - 492s 971us/step - loss: 0.0280 - val_loss: 0.0301\n",
      "Epoch 18/20\n",
      "506580/506580 [==============================] - 487s 962us/step - loss: 0.0280 - val_loss: 0.0300\n",
      "Epoch 19/20\n",
      "506580/506580 [==============================] - 490s 968us/step - loss: 0.0279 - val_loss: 0.0301\n",
      "Epoch 20/20\n",
      "105790/506580 [=====>........................] - ETA: 8:56 - loss: 0.0273"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-c8c56b987892>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mmodel1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3.1\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 963\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    964\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3.1\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1705\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3.1\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1235\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1236\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3.1\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2478\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2479\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3.1\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3.1\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1135\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1137\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1138\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3.1\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1353\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1355\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1356\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1357\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3.1\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1359\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1360\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1361\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1362\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3.1\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1338\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[1;32m-> 1340\u001b[1;33m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[0;32m   1341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "window_len = 15\n",
    "model1 = Sequential()\n",
    "model1.add(LSTM(120, input_shape=(window_len, len(Alphabet)), return_sequences=True))\n",
    "model1.add(Flatten())\n",
    "model1.add(Dropout(0.1))\n",
    "model1.add(Dense(len(Alphabet),activation='softmax'))\n",
    "model1.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "model1.summary()\n",
    "model1.fit(X_train,Y_train, epochs=20,validation_data = (X_test, Y_test), batch_size=10, verbose=1,callbacks=[callback])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверяем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.save('Pushkin2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Уж небо осенью слава,И всё по светлом полетал,И с под сенью, поступный возведь весь веселый взосленных,С первых лет под волновал своей положит,И с тобой пред ним странный свет под вечерный полон,В своих под сенью подобной полон воздохнет страна своему странный свет под вечерный полон вознеслись под себя возврата не смеря,Не прихот и в подарился.Но всё тебя не вознеслись под сенью:Но скоро ль на сверенный светел,Иль в сердце послушная под старик, в тебя в последний рад, с тобою, странной приходит в полуночи,И сладострастья в сердце пред ним своем под сенью подобной полон воздохнуть под сенью на свое подарит:Без под вечерней под сени,Свои пред тобою,И слезы с подобрать в последний разговор,И сладострастной струится в темной под своих день,И в сердце простой верный свет, —Не вознес и волны.Пред ним старый свое восторгов прихоти не приходит на берег восторгов прихоти не приходит на свое вечерней,И сладостно странный страстному странный старик,Под сенью воспоминание странный свой тебя в последний разговор\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "text = 'Уж небо осенью '\n",
    "text1 = deepcopy(text)\n",
    "from numpy import random\n",
    "random.seed(0)\n",
    "for i in range(1000):\n",
    "    text_array = np.array(string_vectorizer(text1)).reshape(1,window_len,91)\n",
    "    predicted_vector = model1.predict(text_array)\n",
    "    j = random.randint(0,40)\n",
    "    if j%35!=0:\n",
    "        predicted_char = vector_stringizer(predicted_vector[0], return_first=True)\n",
    "    else:\n",
    "        predicted_char = vector_stringizer(predicted_vector[0], return_first=False)\n",
    "    text = text+predicted_char\n",
    "    text1 = text1[1:]+predicted_char\n",
    "    #if i%20==0:\n",
    "        #print('Predicted '+str(i)+' letters ')\n",
    "print(text) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вроде, немного получше. А что если расширить выборку? Добавить к стихам поэмы?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'string_vectorizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-918ef5926c26>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m#We don't delete any of the chars as now\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mdata_onehot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstring_vectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[0mwindow_len\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mX_total\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_total\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'string_vectorizer' is not defined"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "text=open('Стихи+Поэмы.txt','r').readlines()\n",
    "text = [i for i in text if i != '' and 'Стихотворения' not in i]\n",
    "text = [i.strip() for i in text]\n",
    "text = text[:len(text)-243]\n",
    "data=''.join(text)\n",
    "data = data.replace('\\xa0',' ')\n",
    "\n",
    "for number in '123456789':\n",
    "    data=data.replace(number,'0')\n",
    "for english_letter in 'ABCDEFGHIJKLMNOPQRSTUVWXYZ':\n",
    "    data=data.replace(english_letter, '')\n",
    "for english_letter in 'abcdefghijklmnopqrstuvwzyz':\n",
    "    data=data.replace(english_letter, '')    \n",
    "b=set(data)\n",
    "c=dict()\n",
    "for symbol in b:\n",
    "    c[symbol] = data.count(symbol)\n",
    "import operator\n",
    "c1 = sorted(c.items(), key=operator.itemgetter(1))\n",
    "Alphabet =''.join(c.keys())\n",
    "Alphabet\n",
    "#We don't delete any of the chars as now\n",
    "\n",
    "data_onehot = string_vectorizer(data)\n",
    "window_len = 15\n",
    "X_total,Y_total=[],[]\n",
    "def make_dataset(data_onehot):\n",
    "    X_total,Y_total=[],[]\n",
    "    for i in tqdm(range(window_len, len(data_onehot))):\n",
    "        X_total.append(data_onehot[i-window_len:i])\n",
    "        Y_total.append(data_onehot[i])\n",
    "    return np.array(X_total), np.array(Y_total)\n",
    "X_total, Y_total=make_dataset(data_onehot)\n",
    "del tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(X_total, Y_total, test_size=0.15, random_state = 1)\n",
    "del X_total\n",
    "del  Y_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "del sys.modules[\"tqdm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tqdm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-f288ff9f5818>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtqdm\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'tqdm' is not defined"
     ]
    }
   ],
   "source": [
    "tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_6 (LSTM)                (None, 15, 120)           103680    \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 1800)              0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 1800)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 95)                171095    \n",
      "=================================================================\n",
      "Total params: 274,775\n",
      "Trainable params: 274,775\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 906445 samples, validate on 159961 samples\n",
      "Epoch 1/20\n",
      " - 891s - loss: 0.0342 - val_loss: 0.0314\n",
      "Epoch 2/20\n",
      " - 923s - loss: 0.0309 - val_loss: 0.0298\n",
      "Epoch 3/20\n",
      " - 855s - loss: 0.0297 - val_loss: 0.0293\n",
      "Epoch 4/20\n",
      " - 844s - loss: 0.0291 - val_loss: 0.0289\n",
      "Epoch 5/20\n",
      " - 845s - loss: 0.0287 - val_loss: 0.0286\n",
      "Epoch 6/20\n",
      " - 842s - loss: 0.0285 - val_loss: 0.0286\n",
      "Epoch 7/20\n",
      " - 845s - loss: 0.0282 - val_loss: 0.0284\n",
      "Epoch 8/20\n",
      " - 842s - loss: 0.0280 - val_loss: 0.0284\n",
      "Epoch 9/20\n",
      " - 844s - loss: 0.0279 - val_loss: 0.0282\n",
      "Epoch 10/20\n",
      " - 843s - loss: 0.0278 - val_loss: 0.0283\n",
      "Epoch 11/20\n",
      " - 845s - loss: 0.0277 - val_loss: 0.0281\n",
      "Epoch 12/20\n",
      " - 849s - loss: 0.0276 - val_loss: 0.0281\n",
      "Epoch 13/20\n",
      " - 841s - loss: 0.0275 - val_loss: 0.0281\n",
      "Epoch 14/20\n",
      " - 845s - loss: 0.0274 - val_loss: 0.0280\n",
      "Epoch 15/20\n",
      " - 841s - loss: 0.0274 - val_loss: 0.0280\n",
      "Epoch 16/20\n",
      " - 843s - loss: 0.0273 - val_loss: 0.0280\n",
      "Epoch 17/20\n",
      " - 836s - loss: 0.0273 - val_loss: 0.0280\n",
      "Epoch 18/20\n",
      " - 841s - loss: 0.0272 - val_loss: 0.0280\n",
      "Epoch 19/20\n",
      " - 845s - loss: 0.0272 - val_loss: 0.0280\n",
      "Epoch 20/20\n",
      " - 851s - loss: 0.0271 - val_loss: 0.0281\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xa11e1f28>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_len = 15\n",
    "model2 = Sequential()\n",
    "model2.add(LSTM(120, input_shape=(window_len, len(Alphabet)), return_sequences=True))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dropout(0.1))\n",
    "model2.add(Dense(len(Alphabet),activation='softmax'))\n",
    "model2.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "model2.summary()\n",
    "model2.fit(X_train,Y_train, epochs=20,validation_data = (X_test, Y_test), batch_size=10, verbose=2,callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Уж небо осенью долго в сердце простой не страшно в стране славы старины страны страны, друзья, приятной страны славы,Не стоят пред ним молодой, признаю страх на свете не смелой странный славы,Не достойный страны славы,На свет в страх не стал под сень моей друг, не стал под сень моей друг сердце волны своей свет и страшно в стране славы старины страны страны, другой приятный славы,Пред ним свободно в предан от своей сон он страх не стал под сень моей друг, не стал под сень моей друзья,Как славы славы славы, славы славы славы, славы славы не смелой,И все дружбе, под сень моей друг, славы бессмертный прихотит в нем сердце волны свед,То все друзья молодой,В сердце пред ним страх не стал последний свой долго в нем сестрица своих постели приветствовал он странный славы страны славы,Не подружками странный славы страны славы,Не стал под горами своей свет,То страх сердце полный страх, неверный страны славы,Не стал под городой.Он в старуха странный славы,Не старый страх не страшал он веселой пристали в стране славы страны, славы, слава, страх не следу воспой и славы,И страх и славы старины страны страны слезы приславил над бездной друзья,Когда с неге он не смелой старости странный славы,На свет верной строгой страны славы,Не стал под сень моей друг, не страшно в сердце полный вздохом простой,С бедной странный славы,Не старый восторгов своей на свете,Под сенью моим образ милый друг, не смелой странный славы,Не старый воспоминаний, страх не стал под сень моей друг, не стал под сени, друзья, приятной страх на свете не смелой,И в сени мое советами,Из после видел он не смолить, на берего странный друг, не смелой на своей под сень моей друг, не стал под сень моих душе поэта воспоминаньем, славы бессмертный, долго прославался на берегов, и в поле в стране воспоминанье,На старость он не смелой странный славы,Не старый воспоминанья,И страшит сердце волны, верной страны славы,Не стал под сень моей друг, не стал под сень моей друг, не стал под сень моей друг сердце волны светлый страны славы,Не стал п\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "text = 'Уж небо осенью '\n",
    "text1 = deepcopy(text)\n",
    "from numpy import random\n",
    "random.seed(90)\n",
    "for i in range(2000):\n",
    "    text_array = np.array(string_vectorizer(text1)).reshape(1,window_len,len(Alphabet))\n",
    "    predicted_vector = model2.predict(text_array)\n",
    "    j = random.randint(0,40)\n",
    "    if j%35!=0:\n",
    "        predicted_char = vector_stringizer(predicted_vector[0], return_first=True)\n",
    "    else:\n",
    "        predicted_char = vector_stringizer(predicted_vector[0], return_first=False)\n",
    "    text = text+predicted_char\n",
    "    text1 = text1[1:]+predicted_char\n",
    "    #if i%20==0:\n",
    "        #print('Predicted '+str(i)+' letters ')\n",
    "print(text) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А если всегда только самую вероятную букву?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Уж небо осенью долго в сердце полный взор,И в стране славы старины страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны страны стр\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "text = 'Уж небо осенью '\n",
    "text1 = deepcopy(text)\n",
    "from numpy import random\n",
    "random.seed(0)\n",
    "for i in range(1000):\n",
    "    text_array = np.array(string_vectorizer(text1)).reshape(1,window_len,len(Alphabet))\n",
    "    predicted_vector = model2.predict(text_array)\n",
    "    \n",
    "    predicted_char = vector_stringizer(predicted_vector[0], return_first=True)\n",
    "    text = text+predicted_char\n",
    "    text1 = text1[1:]+predicted_char\n",
    "    #if i%20==0:\n",
    "        #print('Predicted '+str(i)+' letters ')\n",
    "print(text) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ничего хорошего. Хотелось бы помнить больше 15 символов, но вот беда - все в память не помещаются. А если fit_generator попробовать?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "del  X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DK\\Anaconda3.1\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM,Flatten,Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "#from tqdm import tqdm\n",
    "from scipy import sparse\n",
    "from  keras.callbacks import EarlyStopping\n",
    "callback = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='min')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from numpy import random\n",
    "text=open('Стихи+Поэмы.txt','r').readlines()\n",
    "text = [i for i in text if i != '' and 'Стихотворения' not in i]\n",
    "text = [i.strip() for i in text]\n",
    "text = text[:len(text)-243]\n",
    "data=''.join(text)\n",
    "data = data.replace('\\xa0',' ')\n",
    "\n",
    "for number in '123456789':\n",
    "    data=data.replace(number,'0')\n",
    "for english_letter in 'ABCDEFGHIJKLMNOPQRSTUVWXYZ':\n",
    "    data=data.replace(english_letter, '')\n",
    "for english_letter in 'abcdefghijklmnopqrstuvwzyz':\n",
    "    data=data.replace(english_letter, '')    \n",
    "b=set(data)\n",
    "c=dict()\n",
    "for symbol in b:\n",
    "    c[symbol] = data.count(symbol)\n",
    "import operator\n",
    "c1 = sorted(c.items(), key=operator.itemgetter(1))\n",
    "Alphabet =''.join(c.keys())\n",
    "Alphabet\n",
    "#We don't delete any of the chars as now\n",
    "\n",
    "def string_vectorizer(string, alphabet=Alphabet):\n",
    "    vector = [[0 if char != letter else 1 for char in Alphabet] \n",
    "                  for letter in string]\n",
    "    return vector\n",
    "def vector_stringizer(vector, alphabet = Alphabet,return_first=True):\n",
    "    answ=''\n",
    "    if return_first:\n",
    "        index = vector.argsort()[-1]\n",
    "        answ+=Alphabet[index]\n",
    "    else:\n",
    "        index = vector.argsort()[-2]\n",
    "        answ+=Alphabet[index]\n",
    "    return answ\n",
    "data_onehot = string_vectorizer(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_onehot=np.array(data_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=1500\n",
    "window_len=35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=np.arange(window_len, len(data_onehot))\n",
    "random.seed(333)\n",
    "train_set = np.random.choice(np.arange(window_len,len(data_onehot)-window_len), int(0.85*(len(data_onehot)-window_len)), replace=False)\n",
    "test_set=np.array(list(set(np.arange(window_len,len(data_onehot)-window_len))-set(train_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159923"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(train_set):\n",
    "    global g,g0\n",
    "    final_data=None\n",
    "    final_label=None\n",
    "    counter=0\n",
    "    this_count=0\n",
    "    i=0\n",
    "    while True:\n",
    "        data = data_onehot[train_set[i]-window_len:train_set[i],:]\n",
    "        #print(data.shape)\n",
    "        label = data_onehot[train_set[i],:]\n",
    "        if counter==0:\n",
    "            final_data=data.reshape(1,data.shape[0],data.shape[1])\n",
    "            final_label=label.reshape(1,label.shape[0])\n",
    "        else:\n",
    "            data=data.reshape((1,data.shape[0],data.shape[1]))\n",
    "            label=label.reshape((1,label.shape[0]))\n",
    "            try:\n",
    "                final_data=np.concatenate([final_data,data],axis=0)\n",
    "            except:\n",
    "                print(i)\n",
    "                raise Exception(str(i)+' '+str(final_data.shape)+' '+str(data.shape))\n",
    "            try:                                \n",
    "                final_label=np.concatenate([final_label,label],axis=0)\n",
    "            except:\n",
    "                raise Exception(str(final_label.shape)+' '+str(label.shape))    \n",
    "\n",
    "        counter+=1\n",
    "        i=(i+1)%len(train_set)\n",
    "        if counter==batch_size:\n",
    "            if final_data.shape==(batch_size,window_len,len(Alphabet)) and final_label.shape==(batch_size,len(Alphabet)):\n",
    "                yield (final_data,final_label)\n",
    "                this_count+=1\n",
    "                if this_count%15==0:\n",
    "                    print('completed '+str(i*100/len(train_set))+' percent')\n",
    "            else:\n",
    "                print('ERROR')\n",
    "                print(i)\n",
    "                g=final_data,final_label\n",
    "                raise Exception(str(g[0].shape)+' '+str(g[1].shape))\n",
    "            final_data=None\n",
    "            final_label=None\n",
    "            counter=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = train_set[:len(train_set)-(len(train_set)%batch_size)]\n",
    "test_set = test_set[:len(test_set)-(len(test_set)%batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_14 (LSTM)               (None, 35, 120)           103680    \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 4200)              0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 4200)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 95)                399095    \n",
      "=================================================================\n",
      "Total params: 502,775\n",
      "Trainable params: 502,775\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(LSTM(120, input_shape=(window_len, len(Alphabet)), return_sequences=True))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dropout(0.1))\n",
    "model2.add(Dense(len(Alphabet),activation='softmax'))\n",
    "model2.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "completed 2.4834437086092715 percent\n",
      "completed 4.966887417218543 percent\n",
      "completed 7.450331125827814 percent\n",
      "completed 9.933774834437086 percent\n",
      "completed 12.417218543046358 percent\n",
      "completed 14.900662251655628 percent\n",
      "completed 17.3841059602649 percent\n",
      "completed 19.867549668874172 percent\n",
      "completed 22.350993377483444 percent\n",
      "completed 24.834437086092716 percent\n",
      "completed 27.31788079470199 percent\n",
      "completed 29.801324503311257 percent\n",
      "completed 32.28476821192053 percent\n",
      "completed 34.7682119205298 percent\n",
      "completed 37.25165562913907 percent\n",
      "completed 39.735099337748345 percent\n",
      "completed 42.21854304635762 percent\n",
      "completed 44.70198675496689 percent\n",
      "completed 47.18543046357616 percent\n",
      "completed 49.66887417218543 percent\n",
      "completed 52.152317880794705 percent\n",
      "completed 54.63576158940398 percent\n",
      "completed 57.11920529801324 percent\n",
      "completed 59.602649006622514 percent\n",
      "completed 62.086092715231786 percent\n",
      "completed 64.56953642384106 percent\n",
      "completed 67.05298013245033 percent\n",
      "completed 69.5364238410596 percent\n",
      "completed 72.01986754966887 percent\n",
      "completed 74.50331125827815 percent\n",
      "completed 76.98675496688742 percent\n",
      "completed 79.47019867549669 percent\n",
      "completed 81.95364238410596 percent\n",
      "completed 84.43708609271523 percent\n",
      "completed 86.9205298013245 percent\n",
      "completed 89.40397350993378 percent\n",
      "completed 91.88741721854305 percent\n",
      "completed 94.37086092715232 percent\n",
      "completed 96.8543046357616 percent\n",
      "completed 99.33774834437087 percent\n",
      "completed 14.150943396226415 percent\n",
      "completed 28.30188679245283 percent\n",
      "completed 42.45283018867924 percent\n",
      "completed 56.60377358490566 percent\n",
      "completed 70.75471698113208 percent\n",
      "completed 84.90566037735849 percent\n",
      "completed 99.05660377358491 percent\n",
      " - 6787s - loss: 0.0421 - val_loss: 0.0377\n",
      "Epoch 2/20\n",
      "completed 1.8211920529801324 percent\n",
      "completed 4.304635761589404 percent\n",
      "completed 6.788079470198675 percent\n",
      "completed 9.271523178807946 percent\n",
      "completed 11.754966887417218 percent\n",
      "completed 14.23841059602649 percent\n",
      "completed 16.721854304635762 percent\n",
      "completed 19.205298013245034 percent\n",
      "completed 21.688741721854306 percent\n",
      "completed 24.172185430463575 percent\n",
      "completed 26.655629139072847 percent\n",
      "completed 29.13907284768212 percent\n",
      "completed 31.62251655629139 percent\n",
      "completed 34.10596026490066 percent\n",
      "completed 36.58940397350993 percent\n",
      "completed 39.0728476821192 percent\n",
      "completed 41.556291390728475 percent\n",
      "completed 44.03973509933775 percent\n",
      "completed 46.52317880794702 percent\n",
      "completed 49.00662251655629 percent\n",
      "completed 51.49006622516556 percent\n",
      "completed 53.973509933774835 percent\n",
      "completed 56.45695364238411 percent\n",
      "completed 58.94039735099338 percent\n",
      "completed 61.42384105960265 percent\n",
      "completed 63.90728476821192 percent\n",
      "completed 66.3907284768212 percent\n",
      "completed 68.87417218543047 percent\n",
      "completed 71.35761589403974 percent\n",
      "completed 73.84105960264901 percent\n",
      "completed 76.32450331125828 percent\n",
      "completed 78.80794701986756 percent\n",
      "completed 81.29139072847683 percent\n",
      "completed 83.7748344370861 percent\n",
      "completed 86.25827814569537 percent\n",
      "completed 88.74172185430463 percent\n",
      "completed 91.2251655629139 percent\n",
      "completed 93.70860927152317 percent\n",
      "completed 96.19205298013244 percent\n",
      "completed 98.67549668874172 percent\n",
      "completed 1.1589403973509933 percent\n",
      "completed 13.20754716981132 percent\n",
      "completed 27.358490566037737 percent\n",
      "completed 41.509433962264154 percent\n",
      "completed 55.660377358490564 percent\n",
      "completed 69.81132075471699 percent\n",
      "completed 83.9622641509434 percent\n",
      "completed 98.11320754716981 percent\n",
      " - 6538s - loss: 0.0367 - val_loss: 0.0359\n",
      "Epoch 3/20\n",
      "completed 3.642384105960265 percent\n",
      "completed 6.125827814569536 percent\n",
      "completed 8.609271523178808 percent\n",
      "completed 11.092715231788079 percent\n",
      "completed 13.57615894039735 percent\n",
      "completed 16.05960264900662 percent\n",
      "completed 18.543046357615893 percent\n",
      "completed 21.026490066225165 percent\n",
      "completed 23.509933774834437 percent\n",
      "completed 25.99337748344371 percent\n",
      "completed 28.47682119205298 percent\n",
      "completed 30.960264900662253 percent\n",
      "completed 33.443708609271525 percent\n",
      "completed 35.9271523178808 percent\n",
      "completed 38.41059602649007 percent\n",
      "completed 40.89403973509934 percent\n",
      "completed 43.37748344370861 percent\n",
      "completed 45.86092715231788 percent\n",
      "completed 48.34437086092715 percent\n",
      "completed 50.82781456953642 percent\n",
      "completed 53.311258278145694 percent\n",
      "completed 55.794701986754966 percent\n",
      "completed 58.27814569536424 percent\n",
      "completed 60.76158940397351 percent\n",
      "completed 63.24503311258278 percent\n",
      "completed 65.72847682119205 percent\n",
      "completed 68.21192052980132 percent\n",
      "completed 70.69536423841059 percent\n",
      "completed 73.17880794701986 percent\n",
      "completed 75.66225165562913 percent\n",
      "completed 78.1456953642384 percent\n",
      "completed 80.62913907284768 percent\n",
      "completed 83.11258278145695 percent\n",
      "completed 85.59602649006622 percent\n",
      "completed 88.0794701986755 percent\n",
      "completed 90.56291390728477 percent\n",
      "completed 93.04635761589404 percent\n",
      "completed 95.52980132450331 percent\n",
      "completed 98.01324503311258 percent\n",
      "completed 0.4966887417218543 percent\n",
      "completed 12.264150943396226 percent\n",
      "completed 26.41509433962264 percent\n",
      "completed 40.56603773584906 percent\n",
      "completed 54.716981132075475 percent\n",
      "completed 68.86792452830188 percent\n",
      "completed 83.01886792452831 percent\n",
      "completed 97.16981132075472 percent\n",
      " - 6840s - loss: 0.0355 - val_loss: 0.0350\n",
      "Epoch 4/20\n",
      "completed 2.980132450331126 percent\n",
      "completed 5.4635761589403975 percent\n",
      "completed 7.947019867549669 percent\n",
      "completed 10.43046357615894 percent\n",
      "completed 12.913907284768213 percent\n",
      "completed 15.397350993377483 percent\n",
      "completed 17.880794701986755 percent\n",
      "completed 20.364238410596027 percent\n",
      "completed 22.8476821192053 percent\n",
      "completed 25.33112582781457 percent\n",
      "completed 27.814569536423843 percent\n",
      "completed 30.29801324503311 percent\n",
      "completed 32.78145695364238 percent\n",
      "completed 35.264900662251655 percent\n",
      "completed 37.74834437086093 percent\n",
      "completed 40.2317880794702 percent\n",
      "completed 42.71523178807947 percent\n",
      "completed 45.19867549668874 percent\n",
      "completed 47.682119205298015 percent\n",
      "completed 50.16556291390729 percent\n",
      "completed 52.64900662251656 percent\n",
      "completed 55.13245033112583 percent\n",
      "completed 57.615894039735096 percent\n",
      "completed 60.09933774834437 percent\n",
      "completed 62.58278145695364 percent\n",
      "completed 65.06622516556291 percent\n",
      "completed 67.54966887417218 percent\n",
      "completed 70.03311258278146 percent\n",
      "completed 72.51655629139073 percent\n",
      "completed 75.0 percent\n",
      "completed 77.48344370860927 percent\n",
      "completed 79.96688741721854 percent\n"
     ]
    }
   ],
   "source": [
    "model2.fit_generator(\n",
    "    batch_generator(train_set), epochs=20,\n",
    "    steps_per_epoch = len(train_set)//batch_size,\n",
    "    validation_data = batch_generator(test_set),\n",
    "    validation_steps = len(test_set)//batch_size,\n",
    "    verbose=2, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_set)//batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "text = 'Уж небо осенью '\n",
    "text1 = deepcopy(text)\n",
    "from numpy import random\n",
    "random.seed(90)\n",
    "for i in range(2000):\n",
    "    text_array = np.array(string_vectorizer(text1)).reshape(1,window_len,len(Alphabet))\n",
    "    predicted_vector = model2.predict(text_array)\n",
    "    j = random.randint(0,window_len)\n",
    "    if j%35!=0:\n",
    "        predicted_char = vector_stringizer(predicted_vector[0], return_first=True)\n",
    "    else:\n",
    "        predicted_char = vector_stringizer(predicted_vector[0], return_first=False)\n",
    "    text = text+predicted_char\n",
    "    text1 = text1[1:]+predicted_char\n",
    "    #if i%20==0:\n",
    "        #print('Predicted '+str(i)+' letters ')\n",
    "print(text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save('Pushkin3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Alphabet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
